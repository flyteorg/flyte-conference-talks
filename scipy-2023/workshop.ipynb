{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scipy 2023: Production-grade Machine Learning with Flyte\n",
    "\n",
    "This workshop will focus on five facets of production-grade data science:\n",
    "\n",
    "- ‚õ∞Ô∏è Scalability\n",
    "- ‚úÖ Data Quality\n",
    "- üîÑ Reproducibility\n",
    "- üîÇ Recoverability\n",
    "- üîé Auditability\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Learn the basics constructs of Flyte: tasks, workflows, and launchplans\n",
    "- Understand how Flyte orchestrates execution graphs, data, and compute infrastructure\n",
    "- Work with the building blocks for productionizing data science workloads\n",
    "- Learn how to test Flyte code, use CI/CD, and extend Flyte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Flyte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "Follow the instructions in the setup instructions of the [README](./README.md).\n",
    "\n",
    "We'll be using some environment variables throughout this workshop, so let's\n",
    "export them right now:\n",
    "\n",
    "```bash\n",
    "export FLYTECTL_CONFIG=~/.flyte/config-sandbox.yaml\n",
    "export IMAGE=ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flyte Basics\n",
    "\n",
    "Tasks, Workflows, and Launch Plans: the building blocks of Flyte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flytekit` is the Python SDK for Flyte. It's the way data scientists, ML engineers, data engineers, and data analysts write code that will eventually run on a Flyte cluster.\n",
    "\n",
    "Let's take a look at the [workflows/example_00_intro.py](./workflows/example_00_intro.py) script.\n",
    "\n",
    "In it, you'll see a simple pipeline that uses the penguins dataset to train a\n",
    "penguin species classifier. This script introduces three core concepts in Flyte:\n",
    "\n",
    "- `tasks`: the basic unit of compute in Flyte.\n",
    "- `workflows`: an execution graph of tasks.\n",
    "- `launchplans`: a mechanism for executing and reusing workflows.\n",
    "\n",
    "You can run this workflow locally with:\n",
    "\n",
    "```\n",
    "python workflows/example_00_intro.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pyflyte run`\n",
    "\n",
    "Run tasks and workflows locally or on a Flyte cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to run a workflow locally, execute the following command on on your terminal:\n",
    "\n",
    "```bash\n",
    "pyflyte run \\\n",
    "    workflows/example_00_intro.py training_workflow \\\n",
    "    --hyperparameters '{\"C\": 0.01}'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great for the local debugging experience, but what if we want to run this\n",
    "workflow on an actual Flyte cluster?\n",
    "\n",
    "`pyflyte run` also supports this use case through the `--remote` flag.\n",
    "\n",
    "```bash\n",
    "pyflyte --config ~/.flyte/config-sandbox.yaml \\\n",
    "    run --remote \\\n",
    "    --image ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest \\\n",
    "    workflows/example_00_intro.py training_workflow \\\n",
    "    --hyperparameters '{\"C\": 0.01}'\n",
    "```\n",
    "\n",
    "Notice how we're providing two extra flags:\n",
    "- `--config`: this is the path to the Flyte config file, which points `pyflyte run`\n",
    "  to the Flyte cluster endpoint.\n",
    "- `--remote`: this flag tells `pyflyte run` that we want to run the workflow on\n",
    "  a flyte cluster.\n",
    "\n",
    "Once you execute this command, you should see a message that looks like this:\n",
    "\n",
    "```\n",
    "Go to http://localhost:30080/console/projects/flytesnacks/domains/development/executions/ff733ed1039b64067a89 to see execution in the console.\n",
    "```\n",
    "\n",
    "Where `ff733ed1039b64067a89`, in this case, is the execution id of the workflow\n",
    "execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flyte Console\n",
    "\n",
    "A tour of the Flyte console to view workflow progress and status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The `flyteconsole` is the UI component of the Flyte stack. It provides a way to visualize workflows, launch them from the browser, and obtain useful metadata about Flyte entities and their corresponding executions.\n",
    "\n",
    "<image src=\"https://raw.githubusercontent.com/flyteorg/static-resources/main/flytesnacks/getting_started/getting_started_console.gif\" width=\"1000px\">\n",
    "\n",
    "Go to the link provided by the `pyflyte run` command to see the execution in the in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `FlyteRemote`\n",
    "\n",
    "Programmatically run tasks and workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run workflows programmatically using the `FlyteRemote` class. This\n",
    "is useful for:\n",
    "\n",
    "- üìì Running Flyte tasks/workflows within a Jupyter notebook\n",
    "- ü§ñ Running Flyte tasks/workflows as a microservice\n",
    "- üö¢ Integrating Flyte into your CI/CD pipelines, or \n",
    "\n",
    "The code below illustrates how we can import the workflow functions into a Python\n",
    "runtime and execute them on a Flyte cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:30080/console/projects/flytesnacks/domains/development/executions/f00b4149410964e44876'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from workflows import example_00_intro\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_00_intro.training_workflow,\n",
    "    inputs={\n",
    "        \"hyperparameters\": example_00_intro.Hyperparameters(C=0.1, max_iter=5000),\n",
    "        \"test_size\": 0.2,\n",
    "        \"random_state\": 11,\n",
    "    }\n",
    ")\n",
    "remote.generate_console_url(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = remote.wait(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=5000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = execution.outputs.get(\"o0\", LogisticRegression)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling Launchplans\n",
    "\n",
    "Run your workflows on a schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Recall in the `example_00_intro.py` script that we defined a launch plan called\n",
    "`scheduled_training_workflow`. You can activate scheduled launchplans from the CLI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the latest launchplan version:\n",
    "\n",
    "```bash\n",
    "flytectl get launchplan \\\n",
    "    -p flytesnacks -d development \\\n",
    "    scheduled_training_workflow --output yaml --latest  \\\n",
    "    | grep 'version:' -m 1\n",
    "```\n",
    "\n",
    "Expected output:\n",
    "```\n",
    "version: <version>\n",
    "```\n",
    "\n",
    "Using the `flytectl` CLI, activate the launchplan:\n",
    "\n",
    "```bash\n",
    "flytectl update launchplan \\\n",
    "    -p flytesnacks -d development \\\n",
    "    scheduled_training_workflow --version '<version>' --activate\n",
    "```\n",
    "\n",
    "Make sure it's activated:\n",
    "\n",
    "```bash\n",
    "flytectl get launchplan \\\n",
    "    -p flytesnacks -d development \\\n",
    "    scheduled_training_workflow --output yaml --latest \\\n",
    "    | grep ' state:'\n",
    "```\n",
    "\n",
    "Expected output:\n",
    "```\n",
    "state: ACTIVE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use `FlyteRemote` to activate launchplans in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activated scheduled_training_workflow\n"
     ]
    }
   ],
   "source": [
    "lp_id = remote.fetch_launch_plan(name=\"scheduled_training_workflow\").id\n",
    "remote.client.update_launch_plan(lp_id, \"ACTIVE\")\n",
    "print(\"activated scheduled_training_workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the execution for the most recent scheduled run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlyteLiteral id { project: \"flytesnacks\" domain: \"development\" name: \"fcbe6f63596a67d10000\" } spec { launch_plan { resource_type: LAUNCH_PLAN project: \"flytesnacks\" domain: \"development\" name: \"scheduled_training_workflow\" version: \"M2MrgLxOIHJfFcZ-1C2AOQ==\" } metadata { mode: SCHEDULED scheduled_at { seconds: 1689044400 } system_metadata { } } labels { } annotations { } auth_role { } } closure { outputs { uri: \"s3://my-s3-bucket/metadata/propeller/flytesnacks-development-fcbe6f63596a67d10000/end-node/data/0/outputs.pb\" } phase: SUCCEEDED started_at { seconds: 1689044400 nanos: 87098000 } duration { seconds: 77 nanos: 644313000 } created_at { seconds: 1689044400 nanos: 79244000 } updated_at { seconds: 1689044477 nanos: 731411000 } }>\n"
     ]
    }
   ],
   "source": [
    "recent_executions = [\n",
    "    ex for ex in remote.recent_executions()\n",
    "    if ex.spec.launch_plan.name == \"scheduled_training_workflow\"\n",
    "]\n",
    "\n",
    "scheduled_execution = None\n",
    "if recent_executions:\n",
    "    scheduled_execution = recent_executions[0]\n",
    "    scheduled_execution = remote.sync(scheduled_execution)\n",
    "    \n",
    "print(scheduled_execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1, max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = scheduled_execution.outputs.get(\"o0\", LogisticRegression)\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deactivate the schedule with the `flytectl` CLI:\n",
    "\n",
    "```bash\n",
    "flytectl update launchplan \\\n",
    "    -p flytesnacks -d development \\\n",
    "    scheduled_training_workflow --version '<version>' --archive\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with `FlyteRemote`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deactivated scheduled_training_workflow\n"
     ]
    }
   ],
   "source": [
    "remote.client.update_launch_plan(lp_id, \"INACTIVE\")\n",
    "print(\"deactivated scheduled_training_workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è±Ô∏è 15 Minute Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flyte Programming Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<image src=\"static/flyte_programming_model_overview.png\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks as Containerized Functions\n",
    "\n",
    "A core building block for type-safety, statelessness, and reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at Flyte tasks.\n",
    "\n",
    "<image src=\"static/flyte_tasks.png\" width=\"400px\">\n",
    "\n",
    "\n",
    "The `@task`-decorated function looks deceptively simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "from flytekit import task\n",
    "\n",
    "@task\n",
    "def hello():\n",
    "    print(\"hello world\")\n",
    "\n",
    "hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want the task to do anything useful, we want to give it some inputs and\n",
    "have it produce some outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@task\n",
    "def square(x: float) -> float:\n",
    "    return x ** 2\n",
    "\n",
    "square(x=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, notice a two things:\n",
    "\n",
    "- **Tasks functions are strongly typed:** this not only provides type safety,\n",
    "  it allows Flyte to analyze a sequence of tasks that depend on each other\n",
    "  and determine their compatibility.\n",
    "- **Tasks arguments must be kwargs:** this is a current constraint of Flyte tasks\n",
    "  that may be removed in a future release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise**:\n",
    "1. Try calling `square` with a different data type.\n",
    "2. Modify the code in the `square` function to output a different data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Containerized Functions?\n",
    "\n",
    "What does type-safety have to do with containers?\n",
    "\n",
    "Flyte treats tasks as containerized functions. This means that each task runs on\n",
    "their own isolated container in the Flyte cluster. Coupled with strongly-typed\n",
    "interfaces, tasks are essentially ‚ú®microservices‚ú® that can be composed together\n",
    "to form workflows.\n",
    "\n",
    "This entails the following benefits:\n",
    "\n",
    "- **Statelessness:** each task is stateless, which means that it can be run\n",
    "  multiple times without side effects.\n",
    "- **Reproducibility:** each task is reproducible, which means that it can be\n",
    "  run multiple times with the same inputs and produce the same outputs.\n",
    "- **Portability:** each task is portable, which means that it can be run on\n",
    "  any Flyte cluster, or any infrastructure that can run containers.\n",
    "- **Heterogeneity:** each task in a workflow can be written in any language and\n",
    "  can be run with varying compute requirements.\n",
    "\n",
    "Now let's run the `get_data` task from `example_00_intro.py` with pyflyte run:\n",
    "\n",
    "```bash\n",
    "pyflyte --config ~/.flyte/config-sandbox.yaml \\\n",
    "    run --remote \\\n",
    "    --image ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest \\\n",
    "    workflows/example_00_intro.py get_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go to the `flyteconsole` link provided by the `pyflyte run` command, we can\n",
    "dig into the guts of a task container execution:\n",
    "\n",
    "> - In the **Executions** tab, go to the **Logs** link, which will take you to\n",
    "the Kubernetes dashboard logs.\n",
    "> - If you go to the **Pod** metadata description,\n",
    "you can see the **Arguments** that are provided as the entrypoint to the\n",
    "task container.\n",
    "\n",
    "**Exercise**:\n",
    "\n",
    "We can reproduce what happens in the Flyte cluster inside a local docker container:\n",
    "\n",
    "```bash\n",
    "docker run --network=\"host\" -it ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest /bin/bash\n",
    "```\n",
    "\n",
    "Then, inside the container session, run the following command:\n",
    "\n",
    "```bash\n",
    "export FLYTE_SDK_LOGGING_LEVEL=20\n",
    "export AWS_ACCESS_KEY_ID=minio\n",
    "export AWS_SECRET_ACCESS_KEY=miniostorage\n",
    "export FLYTE_AWS_ENDPOINT=http://localhost:30002\n",
    "```\n",
    "\n",
    "Finally, copy-paste the arguments from the **Pod** metadata description in the\n",
    "code-fence below. You'll need to re-format the string so that you can invoke all\n",
    "of the arguments as a single command.\n",
    "\n",
    "```bash\n",
    "pyflyte-fast-execute \\\n",
    "...\n",
    "```\n",
    "\n",
    "If everything worked as expected, you should see some `INFO` logs indicating\n",
    "how long each step of the task execution took.\n",
    "\n",
    "**Takeaway**: The `@task` decorator abstracts away many aspects of the underlying\n",
    "container-native infrastructure that powers Flyte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflows and Promises\n",
    "\n",
    "How Flyte workflows construct an execution graph of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a closer look at Flyte workflows:\n",
    "\n",
    "<image src=\"static/flyte_workflows.png\" width=\"500px\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flyte `@workflow` is basically a domain-specific language (DSL) that builds an\n",
    "execution graph that uses tasks as the building blocks for more complex pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flytekit import workflow\n",
    "\n",
    "@task\n",
    "def error(x: list[float], y: list[float]) -> list[float]:\n",
    "    return [xi - yi for xi, yi in zip(x, y)]\n",
    "\n",
    "@task\n",
    "def squares(x: list[float]) -> list[float]:\n",
    "    return [xi ** 2 for xi in x]\n",
    "\n",
    "@task\n",
    "def sum_task(x: list[float]) -> float:\n",
    "    return sum(x)\n",
    "\n",
    "@workflow\n",
    "def sum_of_squares(x: list[float], y: list[float]) -> float:\n",
    "    errors = error(x=x, y=y)\n",
    "    squared = squares(x=errors)\n",
    "    return sum_task(x=squared)\n",
    "\n",
    "\n",
    "sum_of_squares(x=[1.0, 2.0, 3.0], y=[1.0, 3.0, 6.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "\n",
    "- In the `sum_of_squares` workflow function, print out the `squared` variable. What\n",
    "  do you expect to see? What do you actually see?\n",
    "- Try invoking `sum_of_squares` with different data types.\n",
    "- Modify one of the types in any of the tasks used in the `sum_of_squares` workflow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flyte type system is responsible for a lot of Flyte's production-grade\n",
    "qualities:\n",
    "\n",
    "- üëü Run-time type-checking.\n",
    "- üì¶ Serialization/deserialization of IO between tasks.\n",
    "- üìù Type-checking of workflows at compile-time.\n",
    "\n",
    "This type system is language-agnostic and is implemented in the `flyteidl`\n",
    "protobuf format. This means that Flyte SDKs can be written in any language.\n",
    "Currently `flytekit` is the Python implementation, but there are also\n",
    "Java, Scala, and Javascript SDKs.\n",
    "\n",
    "<image src=\"static/flyte_type_system.png\" width=\"400px\">\n",
    "\n",
    "Take a look at [example_04_type_system.py](./workflows/example_04_type_system.py).\n",
    "\n",
    "Try changing the output signature of `get_data` from `pd.DataFrame` to `dict`\n",
    "and try to run the `get_splits` workflow that uses it:\n",
    "\n",
    "```bash\n",
    "pyflyte run \\\n",
    "    workflows/example_04_type_system.py \\\n",
    "    get_splits --test_size 0.2 --random_state 42\n",
    "```\n",
    "\n",
    "What error do you see?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality: DataFrame Types\n",
    "\n",
    "Flyte can natively handle `pandas.DataFrame` objects (and a few others, like\n",
    "`polars.DataFrame`s), but it has a built-in type for dataframe-like objects called \n",
    "`StructuredDataset`s.\n",
    "\n",
    "This allows Flyte to define types and additional metadata that Flyte can use for\n",
    "run-time and compile-type type checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "0  Adelie            39.1           18.7              181.0       3750.0\n",
       "1  Adelie            39.5           17.4              186.0       3800.0\n",
       "2  Adelie            40.3           18.0              195.0       3250.0\n",
       "4  Adelie            36.7           19.3              193.0       3450.0\n",
       "5  Adelie            39.3           20.6              190.0       3650.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "import pandas as pd\n",
    "from palmerpenguins import load_penguins\n",
    "\n",
    "from flytekit import kwtypes\n",
    "from flytekit.types.structured import StructuredDataset\n",
    "\n",
    "from workflows.example_00_intro import TARGET, FEATURES\n",
    "\n",
    "\n",
    "PenquinsDataset = Annotated[\n",
    "    StructuredDataset,\n",
    "    kwtypes(\n",
    "        species=str,\n",
    "        bill_length_mm=float,\n",
    "        bill_depth_mm=float,\n",
    "        flipper_length_mm=float,\n",
    "        body_mass_g=float,\n",
    "    ),\n",
    "]\n",
    "\n",
    "@task\n",
    "def get_data() -> PenquinsDataset:\n",
    "    return StructuredDataset(load_penguins()[[TARGET] + FEATURES].dropna())\n",
    "\n",
    "structured_data = get_data()\n",
    "structured_data.open(pd.DataFrame).all().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ‚ÑπÔ∏è **Note**: If we were to remove some of the columns in the dataframe, Flyte\n",
    "> would throw an error because the type signature of the output would not match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Data Validation with Pandera\n",
    "\n",
    "Pandera is a data validation tool for dataframe-like objects. In\n",
    "[example_05_pandera_types.py](./workflows/example_05_pandera_types.py), we define\n",
    "a pandera schema that validates the output of `get_data` as well as the DataFrame\n",
    "input of `split_data` at runtime.\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "Uncomment line 49 in the `example_05_pandera_types.py` and run the workflow with\n",
    "`pyflyte run`:\n",
    "\n",
    "```bash\n",
    "pyflyte --config ~/.flyte/config-sandbox.yaml \\\n",
    "    run --remote \\\n",
    "    --image ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest \\\n",
    "    workflows/example_05_pandera_types.py \\\n",
    "    get_splits --test_size 0.2 --random_state 42\n",
    "```\n",
    "\n",
    "What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Data Flows in Flyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If tasks run in their own containers inside the Flyte cluster, how is data passed between them?\n",
    "\n",
    "`flytekit` needs to convert all the Python types into something that the `flyteidl`\n",
    "protobuf type system can understand. This is done by the `flytekit` type engine.\n",
    "We'll learn more about how this works later, but at a high-level, it looks like\n",
    "this:\n",
    "\n",
    "<image src=\"static/flyte_data_flow.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see this diagram in action, let's kick off the `get_splits` workflow from\n",
    "`example_05_pandera_types.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/f56416b1295ef4bf1844\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_05_pandera_types\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_05_pandera_types.get_splits,\n",
    "    inputs={\"test_size\": 0.2}\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the execution completes, we can see the inputs and outputs of each task\n",
    "in the workflow execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the node executions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['end-node', 'n0', 'n1', 'start-node'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.node_executions.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the output of the `get_data` node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://my-s3-bucket/data/ja/f56416b1295ef4bf1844-n0-0/ab2d2aa7e056df20cb57af9e68c3a422'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.node_executions[\"n0\"].outputs[\"o0\"].remote_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the input of the `split_data` node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://my-s3-bucket/data/ja/f56416b1295ef4bf1844-n0-0/ab2d2aa7e056df20cb57af9e68c3a422'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.node_executions[\"n1\"].inputs[\"data\"].remote_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Flyte sandbox cluster actually runs a Minio object store that stores all of\n",
    "the inputs and outputs. We can find them on the Minio dashboard http://localhost:30080/minio, or we can get it through the terminal:\n",
    "\n",
    "```bash\n",
    "export AWS_ACCESS_KEY_ID=minio\n",
    "export AWS_SECRET_ACCESS_KEY=miniostorage\n",
    "aws --endpoint-url http://localhost:30002 s3 ls <s3_path>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifecycle of a Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run a workflow locally, flytekit just runs the tasks in a Python runtime. However, when you run the workflow on a Flyte cluster, a lot of things are happening under the hood.\n",
    "\n",
    "`flytepropeller` is the core engine in the Flyte stack that orchestrates:\n",
    "- the execution of tasks in a particular sequence.\n",
    "- the management of data dependencies between tasks.\n",
    "- the compute infrastructure needed to run a task.\n",
    "- ... and much more.\n",
    "\n",
    "This is a very deep topic that we don't have time to cover in this workshop, but\n",
    "here's a high-level overview of what happens:\n",
    "\n",
    "<image src=\"static/flyte_workflow_lifecycle.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Lifecycle Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, working with Flyte as a data scientist looks like this:\n",
    "\n",
    "- üíª Create and test tasks/workflows locally with `pyflyte run`\n",
    "- üì¶ Build a container for your tasks/workflows\n",
    "- üîÅ Iterate on a Flyte cluster with `pyflyte run --remote`\n",
    "- üöÄ Deploy to production on Flyte cluster using `pyflyte register --non-fast`\n",
    "\n",
    "We haven't gone through the build step, but it would look something like this:\n",
    "\n",
    "```bash\n",
    "docker build . -t ghcr.io/cosmicbboy/flyte-conference-talks:scipy-2023-v0\n",
    "docker push ghcr.io/cosmicbboy/flyte-conference-talks:scipy-2023-v0\n",
    "```\n",
    "\n",
    "If we go to the [`Dockerfile`](./Dockerfile), we can see that this packages up\n",
    "all of the Flyte workflow code and the third-party dependencies into the image.\n",
    "\n",
    "Now let's understand what `pyflyte register` is."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `pyflyte register`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `pyflyte register` zips up all of the source code of your Flyte\n",
    "application.\n",
    "\n",
    "```\n",
    "pyflyte register --project flytesnacks --domain development --image $IMAGE workflows\n",
    "```\n",
    "\n",
    "Flyte supports rapid iteration during development via \"fast registration\" via\n",
    "`pyflyte register`. This zips up all of the source code of your Flyte \n",
    "application and bypasses the need to re-build a docker image with your updated\n",
    "code in it.\n",
    "\n",
    "```bash\n",
    "pyflyte register \\\n",
    "    --image ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest \\\n",
    "    --project flytesnacks \\\n",
    "    --domain development \\\n",
    "    workflows\n",
    "```\n",
    "\n",
    "> ‚ÑπÔ∏è **Note**: You can provide an explicit `--version` flag, but by default `flytekit` will create a version string for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the newly registered `example_00_intro.py` workflow:\n",
    "\n",
    "```bash\n",
    "pyflyte --config ~/.flyte/config-sandbox.yaml \\\n",
    "    run --remote \\\n",
    "    --image ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest \\\n",
    "    workflows/example_00_intro.py training_workflow \\\n",
    "    --hyperparameters '{\"C\": 0.01}'\n",
    "```\n",
    "\n",
    "If we go to the Flyte console link provided the `pyflyte run`, we can understand\n",
    "what happened during the execution by going to the **Task** tag and looking at\n",
    "the `--additional-distribution` flag in the container arguments. The `tar.gz` file\n",
    "is the packaged-up Flyte code in our repository, which `flytekit` understands\n",
    "is the actual task code that we want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `pyflyte register --non-fast`\n",
    "\n",
    "Unlike `pyflyte register`, `pyflyte register --non-fast` *will not* package up\n",
    "the user code and simply use the source code that is present in the image when\n",
    "it was originally built.\n",
    "\n",
    "This is the **recommended** way to deploy to production because it ensures that\n",
    "the source code that is running in production is the same as the source code in\n",
    "the image, since the `tar.gz` *could in theory* be swapped out by a malicious\n",
    "actor.\n",
    "\n",
    "Since we're deploying to production, let's specify the `--domain production` flag.\n",
    "\n",
    "```bash\n",
    "pyflyte register \\\n",
    "    --image ghcr.io/flyteorg/flyte-conference-talks:scipy-2023-latest \\\n",
    "    --project flytesnacks \\\n",
    "    --domain production \\\n",
    "    --non-fast \\\n",
    "    --version v0 \\\n",
    "    workflows\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è±Ô∏è 15 Minute Break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Productionizing Data Science Workloads\n",
    "\n",
    "In this next section, we're primarily going to use `FlyteRemote` to kick-off\n",
    "workflows, read and understand the underlying `flytekit` code, and analyze\n",
    "what exactly happened in `flyteconsole`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelism"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1: Dynamic Workflows\n",
    "\n",
    "Dynamic workflows allow you to create execution graphs on the fly. This allows\n",
    "you to specify for loops over inputs to implement a grid search model tuning\n",
    "workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:30080/console/projects/flytesnacks/domains/development/executions/f7483f3766a8044cc86f'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from workflows import example_01_dynamic\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_01_dynamic.tuning_workflow,\n",
    "    inputs={\n",
    "        \"hyperparam_grid\": [\n",
    "            example_00_intro.Hyperparameters(C=0.1, max_iter=5000),\n",
    "            example_00_intro.Hyperparameters(C=0.01, max_iter=5000),\n",
    "            example_00_intro.Hyperparameters(C=0.001, max_iter=5000),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "remote.generate_console_url(execution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Map Tasks\n",
    "\n",
    "Map tasks enable larger fan-outs of embarrassingly parallel computations compared\n",
    "to dynamic workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/fca97404075754c2fa4c\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_02_map_task\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_02_map_task.tuning_workflow,\n",
    "    inputs={\n",
    "        \"hyperparam_grid\": [\n",
    "            example_00_intro.Hyperparameters(C=0.1, max_iter=5000),\n",
    "            example_00_intro.Hyperparameters(C=0.01, max_iter=5000),\n",
    "            example_00_intro.Hyperparameters(C=0.001, max_iter=5000),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal Scaling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: Plugins\n",
    "\n",
    "Flyte has a plugin system that lets you integrate with a wide variety of\n",
    "data and machine learning tools that help you to scale, like BigQuery,\n",
    "Pyspark, and Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/fa4de104a7afd4d1d857\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_03_plugins\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_03_plugins.training_workflow,\n",
    "    inputs={\n",
    "        \"n_epochs\": 50,\n",
    "        \"hyperparameters\": example_03_plugins.Hyperparameters(\n",
    "            in_dim=4, hidden_dim=100, out_dim=3, learning_rate=0.03\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows import example_notebook_tasks\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_notebook_tasks.data_analysis_wf,\n",
    "    inputs={},\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from workflows import example_container_tasks\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_container_tasks.get_data_wf,\n",
    "    inputs={},\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering from Failure"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caching\n",
    "\n",
    "In [example_07_caching.py](./workflows/example_07_caching.py), we revisit the model-tuning use case using `@dynamic` workflows,\n",
    "showing how caching can help reduce wasted compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/fca9432093c79475888c\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_07_caching\n",
    "from workflows.example_06_reproducibility import Hyperparameters\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_07_caching.tuning_workflow,\n",
    "    inputs={\n",
    "        \"hyperparam_grid\": [\n",
    "            Hyperparameters(alpha=alpha)\n",
    "            for alpha in [10.0, 1.0, 0.1, 0.01, 0.001, 0.0001]\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovering Failed Executions\n",
    "\n",
    "In [example_08_recover_executions.py](./workflows/example_08_recover_executions.py), we see how Flyte\n",
    "provides a mechanism by which you can automatically recover from unexpected failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/f30fc95e6cfa84af19bb\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_08_recover_executions\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_08_recover_executions.tuning_workflow,\n",
    "    inputs={\"alpha_grid\": [100.0, 10.0, 1.0, 0.1, 0.01, 0.001, 0.0001, 0.00001]}\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpointing\n",
    "\n",
    "In [example_09_checkpointing.py](./workflows/example_09_checkpointing.py), we\n",
    "learn about how you can do intra-task checkpoints natively in Flyte to pick\n",
    "up from where you left off in, e.g., a model training task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/f0f29542fe51740e9af4\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_09_checkpointing\n",
    "from workflows.example_06_reproducibility import Hyperparameters\n",
    "from workflows.utils import get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_09_checkpointing.training_workflow,\n",
    "    inputs={\n",
    "        \"n_epochs\": 30,\n",
    "        \"hyperparameters\": Hyperparameters(penalty=\"l1\", random_state=42),\n",
    "    }\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auditing Workflows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization with Flyte Decks\n",
    "\n",
    "In [example_10_flyte_decks.py](./workflows/example_10_flyte_decks.py) we\n",
    "create tasks that produce static html reports that help you understand the\n",
    "inputs/outputs of your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/f03a65384d3814414836\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_10_flyte_decks\n",
    "from workflows.utils import download_deck, get_remote\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_10_flyte_decks.penguins_data_workflow,\n",
    "    inputs={},\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flyte decks for execution f9b47ecb975ad4829a95 downloaded to decks/example_10_decks.html\n"
     ]
    }
   ],
   "source": [
    "download_deck(remote, execution, \"n0\", \"decks/example_10_decks.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing, CI/CD, Extending Flyte\n",
    "\n",
    "In this final section of the workshop, we tie everything together by seeing how\n",
    "to test a `flytekit` project, use CI/CD on a `flytekit` codebase, and extend\n",
    "it for your own use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Unit Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 95% of Flyte tasks that you'll ever write and run are just Python code,\n",
    "and therefore it's extremely easy to test.\n",
    "\n",
    "Let's take a look at the unit tests in [`tests/unit/test_workflows.py`](tests/unit/test_workflows.py). You'll notice a few things:\n",
    "\n",
    "- We're using `pytest` as our test runner, because most tasks and workflows and\n",
    "  be executed locally and \"just work\".\n",
    "- The unit tests verify that the outputs of each workflow are of the expected\n",
    "  types.\n",
    "- We can use `flytekit.testing.task_mock` to mock out tasks types where local\n",
    "  execution is currently not supported, e.g. `ContainerTask`s.\n",
    "- We're using a `clear_cache` fixture to make sure that the workflows that rely\n",
    "  on a cache are cleared (so that the functions actually run)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Integration Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Writing integration tests for `flytekit` is a little more involved. Let's take\n",
    "a look at [`tests/integration/test_workflows.py`](tests/integration/test_workflows.py).\n",
    "You'll notice a few things:\n",
    "\n",
    "- We assume that there's a running local Flyte sandbox.\n",
    "- We assume that the workflows are already registered.\n",
    "- We can use a `FlyteRemote` object to execute workflows on the Flyte cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the core pieces of production-grade data science orchestration is the\n",
    "process of CI/CD that allows you to automate your testing and deployment process.\n",
    "\n",
    "Let's take a look at the [`.github/workflows/build.yaml`](../.github/workflows/build.yaml)\n",
    "file in this repository, which contains the Github action workflows. As you can see, this build process does the following:\n",
    "\n",
    "- Installs the Python dependencies needed to run the tests.\n",
    "- Uses the [`flytectl-setup-action`](https://github.com/unionai-oss/flytectl-setup-action)  github action to get access to the `flytectl` CLI tool\n",
    "- Runs the unit tests.\n",
    "- Starts a Flyte sandbox cluster.\n",
    "- Registers all the examples on the sandbox.\n",
    "\n",
    "> ‚ÑπÔ∏è **Note**: The workflows in the workshop are fairly heavy, so we can't\n",
    "> actually run the integration tests against the sandbox. However, you can,\n",
    "> in a real-world setting, you would connect to a remote Flyte cluster that\n",
    "> is correctly configured to run the workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Github Actions for Deployment\n",
    "\n",
    "We can also use this system to progress workflows from `development > staging > production`.\n",
    "\n",
    "Since Flyte has the core construct of a `domain`, we can use github actions\n",
    "to automate this process. For example:\n",
    "\n",
    "- üöß When a pull request (PR) is opened, register the workflows to `development`\n",
    "- üîé When a PR is merged to `staging`, register the workflows to the `staging` domain\n",
    "- üöÄ When a PR is merged to `main`, register the workflows to `production`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending Flyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decorators\n",
    "\n",
    "The simplest way to extend `flytekit` tasks is with decorators. This is a\n",
    "Python-native way of modifying the behavior of a function by wrapping it in\n",
    "another function.\n",
    "\n",
    "For example, say we want to do something before and/or after the task executes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do something before\n",
      "do something after\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def decorator(fn):\n",
    "\n",
    "    @wraps(fn)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"do something before\")\n",
    "        out = fn(*args, **kwargs)\n",
    "        print(\"do something after\")\n",
    "        return out\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "@task\n",
    "@decorator\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "add_one(x=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, on the Flyte backend, this will run in the same container as the\n",
    "main task function that's doing all of the heavy lifting.\n",
    "\n",
    "This pattern is useful, e.g., when you need to use some kind of external library\n",
    "to set up metrics logging. In fact, the `flytekitplugins.mlflow` plugin uses\n",
    "this pattern."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extending Flyte Decks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flyte decks can be easily extended to support any arbitrary visualization, as\n",
    "we can see in [example_11_extend_flyte_decks.py](./workflows/example_11_extend_flyte_decks.py)\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Come up with a visualization for one of inputs or outputs of any of the tasks\n",
    "in `example_11_extend_flyte_decks.py`, and create a custom Flyte deck for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:30080/console/projects/flytesnacks/domains/development/executions/f9b47ecb975ad4829a95\n"
     ]
    }
   ],
   "source": [
    "from workflows import example_11_extend_flyte_decks\n",
    "from workflows.example_06_reproducibility import Hyperparameters\n",
    "from workflows.utils import download_deck, get_remote\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "remote = get_remote()\n",
    "execution = remote.execute_local_workflow(\n",
    "    example_11_extend_flyte_decks.training_workflow,\n",
    "    inputs={\n",
    "        \"hyperparameters\": Hyperparameters(\n",
    "            penalty=\"l1\", alpha=0.03, random_state=12345\n",
    "        )\n",
    "    },\n",
    ")\n",
    "print(remote.generate_console_url(execution))\n",
    "execution = remote.wait(execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flyte decks for execution f9b47ecb975ad4829a95 downloaded to decks/example_11_decks_n2.html\n"
     ]
    }
   ],
   "source": [
    "download_deck(remote, execution, \"n2\", \"decks/example_11_decks_n2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flyte decks for execution f9b47ecb975ad4829a95 downloaded to decks/example_11_decks_n3.html\n"
     ]
    }
   ],
   "source": [
    "download_deck(remote, execution, \"n3\", \"decks/example_11_decks_n3.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type Plugins\n",
    "\n",
    "If you have a custom class that you want to use as input or output, `flytekit`\n",
    "will fall back on the `flytekit.types.pickle.FlytePickle` type when\n",
    "serializing/deserializing an instance of that class.\n",
    "\n",
    "If you want to customize the way in which your class is serialized/deserialized,\n",
    "you'll need to use the `TypeTransformer` construct.\n",
    "\n",
    "For example, say you have a custom `Dataset` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(object):\n",
    "    def __init__(self, data: list[dict]):\n",
    "        self.data = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to serialize/deserialize this object as a file, you would do something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Type\n",
    "\n",
    "from flytekit import Blob, BlobMetadata, BlobType, FlyteContext, Literal, LiteralType, Scalar, task, workflow\n",
    "from flytekit.extend import TypeTransformer\n",
    "\n",
    "\n",
    "class MyDatasetTransformer(TypeTransformer[MyDataset]):\n",
    "\n",
    "    _TYPE_INFO = BlobType(\n",
    "        format=\"binary\",\n",
    "        dimensionality=BlobType.BlobDimensionality.SINGLE\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyDatasetTransformer, self).__init__(\n",
    "            name=\"mydataset-transformer\", t=MyDataset\n",
    "        )\n",
    "\n",
    "    def get_literal_type(self, t: Type[MyDataset]) -> LiteralType:\n",
    "        \"\"\"Tells the Flytekit type system that ``MyDataset`` should be a file type.\"\"\"\n",
    "        return LiteralType(blob=self._TYPE_INFO)\n",
    "\n",
    "    def to_literal(self,\n",
    "        ctx: FlyteContext,\n",
    "        python_val: MyDataset,\n",
    "        python_type: Type[MyDataset],\n",
    "        expected: LiteralType,\n",
    "    ) -> Literal:\n",
    "        \"\"\"Converts python_val to a Flyte literal.\"\"\"\n",
    "        local_path = ctx.file_access.get_random_local_path()\n",
    "        with open(local_path, mode=\"w\") as f:\n",
    "            json.dump(python_val.data, f)\n",
    "\n",
    "        remote_path = ctx.file_access.get_random_remote_path()\n",
    "        ctx.file_access.upload(local_path, remote_path)\n",
    "        return Literal(\n",
    "            scalar=Scalar(\n",
    "                blob=Blob(\n",
    "                    uri=remote_path,\n",
    "                    metadata=BlobMetadata(type=self._TYPE_INFO)\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def to_python_value(self, ctx: FlyteContext, lv: Literal, expected_python_type: Type[MyDataset]) -> MyDataset:\n",
    "        \"\"\"\n",
    "        In this method, we want to be able to re-hydrate the custom object from Flyte Literal value.\n",
    "        \"\"\"\n",
    "        local_path = ctx.file_access.get_random_local_path()\n",
    "        ctx.file_access.download(lv.scalar.blob.uri, local_path)\n",
    "        with open(local_path) as f:\n",
    "            data = json.load(f)\n",
    "        return MyDataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we register it in the task engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit.extend import TypeEngine\n",
    "\n",
    "TypeEngine.register(MyDatasetTransformer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `MyDataset` in our flyte tasks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@task\n",
    "def generate() -> MyDataset:\n",
    "    return MyDataset([{\"a\": 1}, {\"a\": 2}])\n",
    "\n",
    "\n",
    "@task\n",
    "def consume(d: MyDataset) -> int:\n",
    "    return sum(x[\"a\"] for x in d.data)\n",
    "\n",
    "\n",
    "@workflow\n",
    "def wf() -> int:\n",
    "    return consume(d=generate())\n",
    "\n",
    "wf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we'll cover in this workshop is extending Flyte tasks. `flytekit`\n",
    "provides a few Flyte-native methods for extending tasks, and here we'll cover\n",
    "the concept of task plugins.\n",
    "\n",
    "Similar to the decorator pattern, task plugins allow you to customize the\n",
    "behavior of the task function but gives you more flyte-specific context and\n",
    "metadata.\n",
    "\n",
    "For example, suppose we want to create a sensor that checks for the presence\n",
    "of a file in the blob store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from datetime import timedelta\n",
    "from time import sleep\n",
    "\n",
    "from flytekit.extend import Interface, PythonTask, context_manager\n",
    "\n",
    "\n",
    "class Sensor(PythonTask):\n",
    "    \"\"\"\n",
    "    Add documentation here for your plugin.\n",
    "    This plugin creates an object store file sensor that waits and exits only when the file exists.\n",
    "    \"\"\"\n",
    "\n",
    "    VAR_NAME: str = \"path\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        poll_interval: timedelta = timedelta(seconds=10),\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(Sensor, self).__init__(\n",
    "            task_type=\"object-store-sensor\",\n",
    "            name=name,\n",
    "            task_config=None,\n",
    "            interface=Interface(\n",
    "                inputs={self.VAR_NAME: str},\n",
    "                outputs={self.VAR_NAME: str},\n",
    "            ),\n",
    "            **kwargs,\n",
    "        )\n",
    "        self._poll_interval = poll_interval\n",
    "\n",
    "    def execute(self, **kwargs) -> typing.Any:\n",
    "        path = kwargs[self.VAR_NAME]\n",
    "        ctx = context_manager.FlyteContext.current_context()\n",
    "        user_context = ctx.user_space_params\n",
    "        while True:\n",
    "            user_context.logging.info(f\"Sensing file in path {path}...\")\n",
    "            if ctx.file_access.exists(path):\n",
    "                user_context.logging.info(f\"file in path {path} exists!\")\n",
    "                return path\n",
    "            user_context.logging.warning(f\"file in path {path} does not exists!\")\n",
    "            sleep(self._poll_interval.seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `Sensor` in our workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flytekit import TaskMetadata, task, workflow\n",
    "\n",
    "sensor = Sensor(\n",
    "    name=\"objectstore-sensor\",\n",
    "    metadata=TaskMetadata(retries=10, timeout=timedelta(minutes=20)),\n",
    "    poll_interval=timedelta(seconds=1),\n",
    ")\n",
    "@task\n",
    "def print_file(path: str) -> str:\n",
    "    print(path)\n",
    "    return path\n",
    "\n",
    "@workflow\n",
    "def my_workflow(path: str) -> str:\n",
    "    return print_file(path=sensor(path=path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Run the workflow above, then `touch /tmp/test.txt` in your terminal to see\n",
    "if the workflow succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_workflow(path=\"/tmp/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "üéâ Congrats! üéâ\n",
    "\n",
    "You've made it through to the end of this workshop.\n",
    "\n",
    "To recap, we've:\n",
    "\n",
    "- Learned the basics constructs of Flyte: tasks, workflows, and launchplans\n",
    "- Understood how Flyte orchestrates execution graphs, data, and compute infrastructure\n",
    "- Worked with the building blocks for productionizing data science workloads\n",
    "- Learned how to test Flyte code, use CI/CD, and extend Flyte\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Flyte Docs](https://docs.flyte.org)\n",
    "- [Flyte Slack](https://slack.flyte.org)\n",
    "- [Flyte Github](https://github.com/flyteorg/flyte)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c1aa76aeeda18f711a0c7c067c98817deca9b2faedcaffac8fadd364058945b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
